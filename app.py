# app.py dosyasÄ±

import streamlit as st
import os
import pandas as pd
import numpy as np
from google import genai
from sentence_transformers import SentenceTransformer
from scipy.spatial.distance import cosine

# --- 1. SABÄ°T TANIMLAMALAR ---
# Bu kÄ±sÄ±mlarÄ± Colab'den kopyalayÄ±n
EMBEDDING_MODEL_NAME = "paraphrase-multilingual-mpnet-base-v2"
GENERATION_MODEL = "gemini-2.5-pro" 

# Model ve DataFrame'i Cache'leme (Streamlit performans optimizasyonu)
@st.cache_resource
def load_resources():
    # Veri setini yÃ¼kleme
    df = pd.read_csv("erasmus_dataset.csv") 
    
    # Embedding Modelini yÃ¼kleme
    embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    
    # Embedding'leri oluÅŸturma (Bu kÄ±sÄ±m Colab'den gelmeli, 
    # veya verinizde zaten 'embedding' sÃ¼tunu olmalÄ±)
    documents = df['cevap'].tolist()
    document_embeddings = embedding_model.encode(documents)
    df['embedding'] = list(document_embeddings)

    return df, embedding_model

df, embedding_model = load_resources()

# --- 2. RAG FONKSÄ°YONLARI (HÃ¼cre 3'ten kopyala) ---

def find_most_relevant_document(query: str, df: pd.DataFrame, top_k: int = 1) -> str:
    # ... (HÃ¼cre 3'teki kod) ...
    pass 

def generate_rag_answer(query: str, context: str) -> str:
    # API AnahtarÄ±nÄ± Streamlit Secrets'tan al
    api_key = st.secrets["GEMINI_API_KEY"] 
    os.environ['GEMINI_API_KEY'] = api_key
    client = genai.Client()
    
    # ... (HÃ¼cre 3'teki kodun geri kalanÄ±) ...
    pass

# --- 3. STREAMLIT ARAYÃœZÃœ ---

st.title("ğŸ“ Erasmus RAG Chatbot")
st.markdown("Bu chatbot, Erasmus veri setine dayalÄ± sorularÄ±nÄ±zÄ± Gemini Pro kullanarak yanÄ±tlar.")

# KullanÄ±cÄ±dan API anahtarÄ± yerine, Streamlit Cloud'un Secret yÃ¶netimini kullanÄ±yoruz
if not "GEMINI_API_KEY" in st.secrets:
    st.error("LÃ¼tfen Gemini API anahtarÄ±nÄ± Streamlit Secrets'a ekleyin.")
else:
    # KullanÄ±cÄ±dan metin giriÅŸi alma
    user_query = st.text_input("Erasmus programÄ± hakkÄ±nda sorunuz nedir?", key="query_input")

    if user_query:
        with st.spinner("Bilgi aranÄ±yor ve cevap Ã¼retiliyor..."):
            # A. Retrieval (Geri Ã‡ekme)
            context_text = find_most_relevant_document(user_query, df, top_k=2)
            
            # B. Generation (Cevap Ãœretme)
            final_answer = generate_rag_answer(user_query, context_text)
            
            # Sonucu gÃ¶sterme
            st.success("Chatbot CevabÄ±:")
            st.write(final_answer)
            
            with st.expander("KullanÄ±lan Bilgi KaynaÄŸÄ± (Context)"):
                st.markdown(context_text)
